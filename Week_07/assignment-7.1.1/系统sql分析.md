# 系统背景
我司是银行行业的一家头部，之前做了两个应用。一个是关于手机银行某些产品的智能推荐，另外一个是手机银行平台的小程序运行时平台。不管是哪个应用都可能会涉及到全量用户的信息存储，因此对数据库的容量和分库分表的涉及需要有仔细的考量。

# 分析
智能推荐中由于需要在推荐过程中对用户最近一段时间的交易日志和用户信息进行处理并根据此信息进行推荐，因此分了4个库，每个库16张表进行存储。按照每张表存储1000w数据来说，全量数据之外还能有空间剩余。数据量级在亿级。

我们自己参考sharding-jdbc写的分库分表的中间件，通过userId的hash进行模后取余，对应到某张表。路由到表中之后的sql的select范围就非常小了，可以在接受的时间范围内完成交易。

数据库接受的最大挑战是首存数据和数据更新，初始数据是由其他应用存储到数据湖中。我们通过某种方式拿到数据的文本文件，解析后入库。每个库每次入库数据在5kw以上。因此需要在夜间完成入库操作，避免影响业务。通过dbcp连接池获取数据，采用生产者消费者模式，多线程入库，使用preparedStatement的批量入库操作，手动执行事务，公司规范500条executeBatch一次。完成过程中踩了很多坑，比如线程池队列满后提交任务不是等待而是抛异常（之后为了适配业务场景，因为数据不能丢失，自己重写了线程池队列）、手动获取connection就需要手动关闭等等。

千辛万苦，终于在投产当天执行了两个小时后成功完成。
